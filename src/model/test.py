# EDSR çš„ PyTorch å®ç°ï¼Œä¸»è¦ç»“æ„æ˜¯ï¼š
# Headï¼šå·ç§¯ï¼ŒæŠŠè¾“å…¥å›¾åƒå˜æˆç‰¹å¾
# Bodyï¼šæ®‹å·®å—å †å ï¼ˆä¸»è¦å­¦ä¹ èƒ½åŠ›åœ¨è¿™é‡Œï¼‰
# Tailï¼šä¸Šé‡‡æ · + å·ç§¯ï¼Œè¾“å‡ºé«˜åˆ†è¾¨ç‡å›¾åƒ
# load_state_dictï¼šèƒ½è‡ªåŠ¨å…¼å®¹ä¸åŒæ”¾å¤§å€æ•°/é€šé“æ•°çš„é¢„è®­ç»ƒæ¨¡å‹
from model import common

import torch.nn as nn

class ResBlock(nn.Module):
    def __init__(self, n_feats, kernel_size,
                 bias=True, act=nn.ReLU(True), res_scale=1):
        super(ResBlock, self).__init__()
        m = []
        # ç¬¬ä¸€ç»„æ·±åº¦å·ç§¯ + ç‚¹å·ç§¯ + æ¿€æ´»
        m.append(nn.Conv2d(n_feats, n_feats, kernel_size, padding=kernel_size//2, groups=n_feats, bias=bias))
        m.append(nn.Conv2d(n_feats, n_feats, 1, bias=bias))
        m.append(act)
        # ç¬¬äºŒç»„æ·±åº¦å·ç§¯ + ç‚¹å·ç§¯ï¼ˆæ— æ¿€æ´»ï¼‰
        m.append(nn.Conv2d(n_feats, n_feats, kernel_size, padding=kernel_size//2, groups=n_feats, bias=bias))
        m.append(nn.Conv2d(n_feats, n_feats, 1, bias=bias))
        self.body = nn.Sequential(*m)
        self.res_scale = res_scale

    def forward(self, x):
        res = self.body(x).mul(self.res_scale)
        res += x
        return res

class ECA(nn.Module):
    def __init__(self, n_feats, k_size=3):
        super(ECA, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=k_size,
                              padding=(k_size - 1) // 2,
                              bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        y = self.avg_pool(x)                      # [B, C, 1, 1]
        y = y.squeeze(-1).transpose(-1, -2)       # [B, 1, C]
        y = self.conv(y)
        y = self.sigmoid(y).transpose(-1, -2).unsqueeze(-1)  # [B, C, 1, 1]
        return x * y.expand_as(x)

def make_model(args, parent=False):
    net = EDSR(args)
    check_modules(net)
    return net

class EDSR(nn.Module):
    def __init__(self, args, conv=common.default_conv):
        super(EDSR, self).__init__()

        n_resblocks = args.n_resblocks   # æ®‹å·®å—æ•°é‡
        n_feats = args.n_feats           # æ¯å±‚ç‰¹å¾æ•°ï¼ˆé€šé“æ•°ï¼‰
        kernel_size = 3
        scale = args.scale[0]            # æ”¾å¤§å€æ•° (x2/x3/x4)
        act = nn.ReLU(True)              # æ¿€æ´»å‡½æ•°

        self.sub_mean = common.MeanShift(args.rgb_range)
        self.add_mean = common.MeanShift(args.rgb_range, sign=1)
        # sub_mean / add_mean â†’ å›¾åƒå½’ä¸€åŒ–/åå½’ä¸€åŒ–ï¼ˆå‡å»å‡å€¼å†åŠ å›æ¥ï¼‰ï¼Œè®­ç»ƒæ›´ç¨³å®šã€‚

        # define head module
        # ç¬¬ä¸€å±‚å·ç§¯ï¼šæŠŠè¾“å…¥ RGB å›¾åƒï¼ˆ3é€šé“ï¼‰æ˜ å°„åˆ° n_feats ä¸ªç‰¹å¾é€šé“ã€‚
        m_head = [conv(args.n_colors, n_feats, kernel_size)]

        # define body module
        # ç”±ä¸€å † æ®‹å·®å— ResBlock ç»„æˆï¼ˆæ¯ä¸ªåŒ…å« 2 ä¸ªå·ç§¯+ReLU+æ®‹å·®è¿æ¥ï¼‰ã€‚
        # æœ€åå†åŠ ä¸€ä¸ªå·ç§¯ã€‚
        m_body = []
        for _ in range(n_resblocks):
            m_body.append(ResBlock(n_feats, kernel_size, act=act, res_scale=args.res_scale))
            m_body.append(ECA(n_feats))
        m_body.append(conv(n_feats, n_feats, kernel_size))

        # define tail module
        # Upsamplerï¼šä¸Šé‡‡æ ·æ¨¡å—ï¼ˆx2/x3/x4ï¼‰ï¼Œç”¨åƒç´ é‡æ’ï¼ˆpixel shuffleï¼‰å®ç°ã€‚
        # æœ€åä¸€å±‚å·ç§¯ï¼šæŠŠç‰¹å¾å›¾è½¬å› RGB å›¾åƒã€‚
        m_tail = [
            common.Upsampler(conv, scale, n_feats, act=False),
            conv(n_feats, args.n_colors, kernel_size)
        ]

        self.head = nn.Sequential(*m_head)
        self.body = nn.Sequential(*m_body)
        self.tail = nn.Sequential(*m_tail)
    # è¾“å…¥å›¾åƒ â†’ å½’ä¸€åŒ– â†’ å·ç§¯æ˜ å°„ â†’ æ®‹å·®å—å †å  â†’ ä¸Šé‡‡æ · â†’ è¾“å‡ºè¶…åˆ†è¾¨å›¾åƒã€‚
    def forward(self, x):
        x = self.sub_mean(x)
        x = self.head(x)

        res = self.body(x)
        res += x

        x = self.tail(res)
        x = self.add_mean(x)

        return x 
    # è¿™æ˜¯è‡ªå®šä¹‰çš„æƒé‡åŠ è½½å‡½æ•°ï¼š
    # å¦‚æœæƒé‡ç»´åº¦åŒ¹é… â†’ æ­£å¸¸åŠ è½½
    # å¦‚æœä¸åŒ¹é…ä¸”ä¸æ˜¯ tail å±‚ â†’ æŠ¥é”™
    # tail å±‚æ˜¯æœ€åè¾“å‡ºå±‚ï¼ˆä¸åŒå€æ•°æ—¶å¤§å°å¯èƒ½ä¸åŒï¼‰ï¼Œæ‰€ä»¥å¯ä»¥å¿½ç•¥ä¸åŒ¹é…
    # ğŸ‘‰ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰æ—¶å€™çœ‹åˆ° strict=Falseï¼Œå®ƒå…è®¸â€œéƒ¨åˆ†åŠ è½½â€ï¼Œæ¯”å¦‚è¿ç§»å­¦ä¹ ã€‚
    def load_state_dict(self, state_dict, strict=True):
        own_state = self.state_dict()
        for name, param in state_dict.items():
            if name in own_state:
                if isinstance(param, nn.Parameter):
                    param = param.data
                try:
                    own_state[name].copy_(param)
                except Exception:
                    if name.find('tail') == -1:
                        raise RuntimeError('While copying the parameter named {}, '
                                           'whose dimensions in the model are {} and '
                                           'whose dimensions in the checkpoint are {}.'
                                           .format(name, own_state[name].size(), param.size()))
            elif strict:
                if name.find('tail') == -1:
                    raise KeyError('unexpected key "{}" in state_dict'
                                   .format(name))
def check_modules(net):
    params = sum(p.numel() for p in net.parameters())
    print(f"Params: {params/1e3:.1f}K")
